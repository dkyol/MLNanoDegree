{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "30309\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile \n",
    "import numpy as np \n",
    "\n",
    "from IPython.display import display \n",
    "\n",
    "data = pd.read_excel('Clean_PA_Data_trunk.xlsx', sheetname ='Sheet1')\n",
    "\n",
    "data2 = pd.read_excel('Clean_PA_Data.xlsx', sheetname = 'Sheet1')\n",
    "\n",
    "print(data.shape[0])\n",
    "\n",
    "print(data2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30282\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "#seperate enrollments and non enrollments | drop uneeded column \n",
    "\n",
    "enrollments = data[data.Label == 1]\n",
    "enrollments = enrollments.drop('Usage Period 1', axis = 1)\n",
    "\n",
    "nonenrollments = data2[data2.Label == 0]\n",
    "nonenrollments = nonenrollments.drop('Usage Period 1', axis = 1)\n",
    "\n",
    "print(nonenrollments.shape[0])\n",
    "print(enrollments.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take # of samples of non-enrollment data set and add it to enrollment data\n",
    "\n",
    "def takeSample (success , failure):\n",
    "    # create twenty combined data sets and fit to data \n",
    "    for x in range(1):\n",
    "        failure = failure.sample( 54, replace = False )\n",
    "        \n",
    "        #print(failure.shape[0])\n",
    "        #print(success.shape[0])\n",
    "        \n",
    "        combined = pd.concat([failure, success])\n",
    "        \n",
    "        X = combined.drop('Label', axis = 1)\n",
    "        y = combined['Label']\n",
    "    \n",
    "        print(\"sample size:\",combined.shape[0]) \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score, recall_score \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    " \n",
    "\n",
    "def runModel(number):\n",
    "    for x in range(number):\n",
    "        \n",
    "        X, y = takeSample(enrollments, nonenrollments)\n",
    "        \n",
    "        #Split Data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =.5, random_state = 0)\n",
    "\n",
    "        #print(\"train size:\", X_train.shape[0])\n",
    "        #print(\"test size\", X_test.shape[0])\n",
    "        \n",
    "        #evluation parameters \n",
    "        beta = .6 \n",
    "        parameters = {'n_estimators' : [1,4,8,16,32,64]}\n",
    "        score = make_scorer(recall_score)\n",
    "        \n",
    "        model = AdaBoostClassifier(random_state =0)\n",
    "        \n",
    "        grid_obj = GridSearchCV(model, parameters, scoring = score)\n",
    "        \n",
    "        model_fit = grid_obj.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = model_fit.best_estimator_\n",
    "        \n",
    "        importances = best_model.feature_importances_ \n",
    "        \n",
    "        best_model_predictions = best_model.predict(X_test)\n",
    "        \n",
    "        best_recall_score = recall_score(y_test, best_model_predictions, beta)\n",
    "        \n",
    "        importances = best_model.feature_importances_ \n",
    "        \n",
    "        print(\"recall score:\", best_recall_score)\n",
    "        \n",
    "        #print(importances)\n",
    "        \n",
    "        #fbest_test_score = fbeta_score(y_test, best_predictions_test, beta)\n",
    "\n",
    "        #acc_test_score = accuracy_score(y_test, best_predictions_test, beta)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 81\n",
      "recall score: 0.466666666667\n",
      "sample size: 81\n",
      "recall score: 0.933333333333\n",
      "sample size: 81\n",
      "recall score: 0.6\n",
      "sample size: 81\n",
      "recall score: 0.6\n",
      "sample size: 81\n",
      "recall score: 0.4\n",
      "sample size: 81\n",
      "recall score: 0.266666666667\n",
      "sample size: 81\n",
      "recall score: 0.333333333333\n",
      "sample size: 81\n",
      "recall score: 0.6\n",
      "sample size: 81\n",
      "recall score: 0.466666666667\n",
      "sample size: 81\n",
      "recall score: 0.466666666667\n",
      "sample size: 81\n",
      "recall score: 0.4\n",
      "sample size: 81\n",
      "recall score: 0.533333333333\n",
      "sample size: 81\n",
      "recall score: 0.466666666667\n",
      "sample size: 81\n",
      "recall score: 0.4\n",
      "sample size: 81\n",
      "recall score: 0.266666666667\n",
      "sample size: 81\n",
      "recall score: 0.4\n",
      "sample size: 81\n",
      "recall score: 0.466666666667\n",
      "sample size: 81\n",
      "recall score: 0.6\n",
      "sample size: 81\n",
      "recall score: 0.0\n",
      "sample size: 81\n",
      "recall score: 0.266666666667\n",
      "sample size: 81\n",
      "recall score: 0.466666666667\n",
      "sample size: 81\n",
      "recall score: 0.2\n",
      "sample size: 81\n",
      "recall score: 0.4\n",
      "sample size: 81\n",
      "recall score: 0.533333333333\n",
      "sample size: 81\n",
      "recall score: 0.466666666667\n"
     ]
    }
   ],
   "source": [
    "runModel(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
